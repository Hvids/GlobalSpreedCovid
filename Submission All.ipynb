{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, BatchNormalization\n",
    "from datetime import datetime, timedelta,date\n",
    "from mapper import mapper_ru,mapper_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_time_series = './data/COVID-19_plus_Russia/csse_covid_19_data/csse_covid_19_time_series/'\n",
    "recovered_global_name = 'time_series_covid19_recovered_global.csv'\n",
    "recovered_ru_name = 'time_series_covid19_confirmed_RU.csv'\n",
    "deaths_global_name = 'time_series_covid19_deaths_global.csv'\n",
    "deaths_ru_name = 'time_series_covid19_deaths_RU.csv'\n",
    "path = './data/'\n",
    "countries_data_name = 'countries.csv'\n",
    "russia_regions_name = 'russia_regions.csv'\n",
    "sample_submission = 'sample_submission.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prediction:\n",
    "    def __init__(self, model,last_date,columns_df):\n",
    "        self.columns_df = columns_df\n",
    "        self.model = model\n",
    "        self.last_date = last_date\n",
    "        self.predion_date = self.__make_date_predition()\n",
    "        self.size_prediction = len(self.predion_date)\n",
    "        \n",
    "    def predict(self,dataset,n_features):\n",
    "        self.dateset = dataset\n",
    "        matrix_prediction = self.__make_prediction_matrix(n_features)\n",
    "        return self.__make_dataframe_prediction(matrix_prediction)\n",
    "    \n",
    "    def __make_dataframe_prediction(self,matrix_prediction):\n",
    "        df = pd.DataFrame(matrix_prediction,columns=self.columns_df)\n",
    "        df['date'] = self.predion_date\n",
    "        return df\n",
    "    def __make_prediction_matrix(self,n_features):\n",
    "        dataset = self.dateset\n",
    "        model = self.model\n",
    "        count = self.size_prediction\n",
    "        \n",
    "        x = np.array([dataset[-3:,:]])\n",
    "        x_i = dataset[-2:,:]\n",
    "        result = []\n",
    "        for _ in range(count):\n",
    "            y_pred = model.predict(x)[0]\n",
    "    #         y_pred_ = list(np.sign(y_pred)*(y_pred))\n",
    "            y_pred_ = list((y_pred))\n",
    "            result.append(y_pred_)\n",
    "            y_pred = y_pred.reshape(1,n_features)\n",
    "            x = np.vstack((x_i,y_pred))\n",
    "            x_i = x[-2:,:]\n",
    "            x = np.array([x])\n",
    "        return result\n",
    "        \n",
    "    def __make_date_predition(self):\n",
    "        last_date = self.last_date\n",
    "        last_date += timedelta(days=1)\n",
    "        res_date = []\n",
    "        while last_date< date(2021,1,1):\n",
    "            res_date.append(last_date)\n",
    "            last_date += timedelta(days=1)\n",
    "        return res_date\n",
    "        \n",
    "        \n",
    "    \n",
    "class Submission:\n",
    "    def __init__(self,columns_df,date_prediction):\n",
    "        self.columns_df = columns_df\n",
    "        self.date_prediction = date_prediction\n",
    "        \n",
    "    def submit(self,rec_df,deaths_df,mapper):\n",
    "        df_res = pd.DataFrame({}) \n",
    "        for column in self.columns_df:\n",
    "            df_res_ = pd.DataFrame({}) \n",
    "            df_res_['date'] = self.date_prediction\n",
    "            df_res_['region'] = [column]*len(self.date_prediction)\n",
    "            df_res_['prediction_confirmed'] = rec_df[column]\n",
    "            df_res_['prediction_deaths'] = deaths_df[column]\n",
    "            \n",
    "            df_res = pd.concat([df_res,df_res_],axis=0)\n",
    "        df_res.index=np.arange(df_res.shape[0])\n",
    "        df_res.region = df_res.region.map(mapper)\n",
    "        return df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps):\n",
    "    n = sequences.shape[0]\n",
    "    X, y = list(), list()\n",
    "    for i in range(n):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "    # check if we are beyond the dataset\n",
    "        if end_ix > n-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix, :]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def build_model_simple(n_steps,n_features):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(n_features, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "    # model.add(RepeatVector(n_features))\n",
    "    model.add(LSTM(n_features, activation='relu'))\n",
    "    \n",
    "    # model.add(LSTM(n_features, activation='relu'))\n",
    "\n",
    "    # model.add(Dense(n_features*4,activation='relu'))\n",
    "    # model.add(Dropout(0.5))\n",
    "    model.add(Dense(n_features*3,activation='relu'))\n",
    "    # model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(n_features*2,activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(n_features,activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(n_features))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_ru(df):\n",
    "    df = pd.concat([df.iloc[:,6:7], df.iloc[:,11:]],axis=1)\n",
    "    return df\n",
    "def get_dataset_ru(df):\n",
    "    solution_df = pd.DataFrame({'name':df['Province_State'].values})\n",
    "    date = df.columns.values[1:]\n",
    "    solution = pd.concat([solution_df,df[date]],axis=1)\n",
    "    dataset = solution[date].values.T \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "recovered_ru = pd.read_csv(path_time_series+ recovered_ru_name)\n",
    "deaths_ru = pd.read_csv(path_time_series + deaths_ru_name)\n",
    "recovered_ru = pre_ru(recovered_ru)\n",
    "deaths_ru = pre_ru(deaths_ru)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RECOVERED RU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dropout' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3b98c14393a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mn_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_rec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel_rec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mX_rec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_rec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_rec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mhisoty_rec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_rec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_rec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_rec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-25cec89fb47b>\u001b[0m in \u001b[0;36mbuild_model_simple\u001b[0;34m(n_steps, n_features)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# model.add(BatchNormalization())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dropout' is not defined"
     ]
    }
   ],
   "source": [
    "dataset_rec = get_dataset_ru(recovered_ru) \n",
    "\n",
    "n_steps = 3\n",
    "n_features = dataset_rec.shape[1]\n",
    "model_rec = build_model_simple(n_steps,n_features)\n",
    "X_rec,y_rec = split_sequences(dataset_rec,n_steps)\n",
    "hisoty_rec = model_rec.fit(X_rec, y_rec, epochs=EPOCHS, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEATHS RU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_deaths = get_dataset_ru(deaths_ru) \n",
    "n_steps = 3\n",
    "n_features =dataset_deaths.shape[1]\n",
    "model_deaths = build_model_simple(n_steps,n_features)\n",
    "\n",
    "\n",
    "X_deaths,y_deaths = split_sequences(dataset_deaths,n_steps)\n",
    "hisoty_deaths = model_deaths.fit(X_deaths, y_deaths, epochs=EPOCHS, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_ru = recovered_ru['Province_State']\n",
    "last_date = pd.to_datetime(recovered_ru.columns.values[-1:]).date[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictioner_rec = Prediction(model_rec,last_date,columns_ru)\n",
    "df_pred_rec = predictioner_rec.predict(dataset_rec,n_features)\n",
    "predictioner_deaths = Prediction(model_deaths,last_date,columns_ru)\n",
    "df_pred_deaths = predictioner_deaths.predict(dataset_deaths,n_features)\n",
    "submissioner = Submission(columns_ru,predictioner_rec.predion_date)\n",
    "subm_ru = submissioner.submit(df_pred_rec,df_pred_deaths,mapper_ru)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLOBAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_global(df, columns_uniq):\n",
    "    df = pd.concat([df.iloc[:,1:2], df.iloc[:,4:]],axis=1)\n",
    "#     print(df)\n",
    "    for country in columns_uniq:\n",
    "#         print(country)\n",
    "        idx = df['Country/Region']==country\n",
    "        idx_n =df['Country/Region']!=country\n",
    "        df_ = pd.DataFrame((df[idx].iloc[:,1:].sum(axis=0))).T\n",
    "        df_['Country/Region'] = country\n",
    "        cols = df_.columns.tolist()\n",
    "        cols = cols[-1:] + cols[:-1]\n",
    "        df_ = df_[cols]\n",
    "        df = df[idx_n]\n",
    "        df = pd.concat([df,df_],axis=0)\n",
    "    df.index = np.arange(df.shape[0])\n",
    "    return df\n",
    "\n",
    "def get_dataset_global(df):\n",
    "    solution_df = pd.DataFrame({'name':df['Country/Region'].values})\n",
    "    date = df.columns.values[1:]\n",
    "    solution = pd.concat([solution_df,df[date]],axis=1)\n",
    "    dataset = solution[date].values.T \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recovered_global = pd.read_csv(path_time_series+ recovered_global_name)\n",
    "deaths_global = pd.read_csv(path_time_series + deaths_global_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_rec = ['China', 'Australia', 'Denmark',\"Demark\", \"France\", 'Netherlands','United Kingdom']\n",
    "uniq_global = ['China', 'Australia', 'Denmark',\"Demark\", \"France\", 'Netherlands','United Kingdom','Canada']\n",
    "\n",
    "recovered_global = pre_global(recovered_global,uniq_rec)\n",
    "deaths_global = pre_global(deaths_global,uniq_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RECOVERED GLOBAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_rec = get_dataset_global(recovered_global) \n",
    "\n",
    "n_steps = 3\n",
    "n_features = dataset_rec.shape[1]\n",
    "model_rec = build_model_simple(n_steps,n_features)\n",
    "\n",
    "\n",
    "X_rec,y_rec = split_sequences(dataset_rec,n_steps)\n",
    "hisoty_rec = model_rec.fit(X_rec, y_rec, epochs=EPOCHS, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEATHS GLOBAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_deaths = get_dataset_global(deaths_global) \n",
    "\n",
    "n_steps = 3\n",
    "n_features = dataset_deaths.shape[1] \n",
    "model_deaths = build_model_simple(n_steps,n_features)\n",
    "X_deaths,y_deaths = split_sequences(dataset_deaths,n_steps)\n",
    "hisoty_deaths = model_deaths.fit(X_deaths, y_deaths, epochs=EPOCHS, verbose=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_global = recovered_global['Country/Region']\n",
    "last_date = pd.to_datetime(recovered_global.columns.values[-1:]).date[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictioner_rec = Prediction(model_rec,last_date,columns_global)\n",
    "df_pred_rec = predictioner_rec.predict(dataset_rec,n_features)\n",
    "predictioner_deaths = Prediction(model_deaths,last_date,columns_global)\n",
    "df_pred_deaths = predictioner_deaths.predict(dataset_deaths,n_features)\n",
    "submissioner = Submission(columns_global,predictioner_rec.predion_date)\n",
    "subm_global = submissioner.submit(df_pred_rec,df_pred_deaths,mapper_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Union Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_union = pd.concat([subm_ru,subm_global],axis=0)\n",
    "solution_union = solution_union.dropna()\n",
    "solution_union.index = np.arange(solution_union.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "solution_union.prediction_confirmed = solution_union.prediction_confirmed.apply(lambda x: round(x) if x>=0 else 0)\n",
    "solution_union.prediction_deaths = solution_union.prediction_deaths.apply(lambda x: round(x) if x>=0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_union.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_union.to_csv('solution.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
