{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, BatchNormalization\n",
    "from datetime import datetime, timedelta,date\n",
    "from mapper import mapper_ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_time_series = './data/COVID-19_plus_Russia/csse_covid_19_data/csse_covid_19_time_series/'\n",
    "recovered_global_name = 'time_series_covid19_recovered_global.csv'\n",
    "recovered_ru_name = 'time_series_covid19_confirmed_RU.csv'\n",
    "deaths_global_name = 'time_series_covid19_deaths_global.csv'\n",
    "deaths_ru_name = 'time_series_covid19_deaths_RU.csv'\n",
    "path = './data/'\n",
    "countries_data_name = 'countries.csv'\n",
    "russia_regions_name = 'russia_regions.csv'\n",
    "sample_submission = 'sample_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "russia_regions = pd.read_csv(path+russia_regions_name)\n",
    "recovered_ru = pd.read_csv(path_time_series+ recovered_ru_name)\n",
    "deaths_ru = pd.read_csv(path_time_series + deaths_ru_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_ru(df):\n",
    "    df = pd.concat([df.iloc[:,6:7], df.iloc[:,11:]],axis=1)\n",
    "    return df\n",
    "recovered_ru = pre_ru(recovered_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_ru(df_ru):\n",
    "    solution_df = pd.DataFrame({'name':df_ru['Province_State'].values})\n",
    "    date = df_ru.columns.values[1:]\n",
    "    solution = pd.concat([solution_df,df_ru[date]],axis=1)\n",
    "    dataset_ru = solution[date].values.T \n",
    "    return dataset_ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps):\n",
    "    n = sequences.shape[0]\n",
    "    X, y = list(), list()\n",
    "    for i in range(n):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "    # check if we are beyond the dataset\n",
    "        if end_ix > n-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix, :]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_simple(n_steps,n_features):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(85, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "    model.add(LSTM(85, activation='relu'))\n",
    "    model.add(Dense(170,activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(n_features))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tscv1\n",
      "14/14 [==============================] - 4s 320ms/step\n",
      " tscv2\n",
      "14/14 [==============================] - 5s 327ms/step\n",
      " tscv3\n",
      "14/14 [==============================] - 5s 339ms/step\n",
      " tscv4\n",
      "14/14 [==============================] - 5s 343ms/step\n",
      " tscv5\n",
      "14/14 [==============================] - 9s 664ms/step\n",
      "364361.1150873661\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit()\n",
    "\n",
    "n_steps = 7\n",
    "n_features = 85\n",
    "model_rec = build_model_simple(n_steps,n_features)\n",
    "\n",
    "dataset_rec = get_dataset_ru(recovered_ru) \n",
    "X_rec,y_rec = split_sequences(dataset_rec,n_steps)\n",
    "i = 0\n",
    "scores = []\n",
    "for train_index, test_index in tscv.split(X_rec):\n",
    "    i+=1\n",
    "    print(f' tscv{i}')\n",
    "    X_train, X_test = X_rec[train_index], X_rec[test_index]\n",
    "    y_train, y_test = y_rec[train_index], y_rec[test_index]\n",
    "    model_tscv = build_model_simple(n_steps,n_features)\n",
    "    model_tscv.fit(X_train, y_train, epochs=100, verbose=0)\n",
    "    score = model_tscv.evaluate(X_test,y_test)\n",
    "    scores.append(score)\n",
    "    \n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hvidsmen/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/10\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 1461074.1962\n",
      "Epoch 2/10\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 1404192.0811\n",
      "Epoch 3/10\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 1372711.9234\n",
      "Epoch 4/10\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 1353051.4603\n",
      "Epoch 5/10\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 1296284.4993\n",
      "Epoch 6/10\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 1201192.9086\n",
      "Epoch 7/10\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 1042333.1156\n",
      "Epoch 8/10\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 884438.8306\n",
      "Epoch 9/10\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 785047.2648\n",
      "Epoch 10/10\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 629469.6881\n"
     ]
    }
   ],
   "source": [
    "n_steps = 3\n",
    "n_features = 85\n",
    "model_rec = build_model_simple(n_steps,n_features)\n",
    "\n",
    "dataset_rec = get_dataset_ru(recovered_ru) \n",
    "X_rec,y_rec = split_sequences(dataset_rec,n_steps)\n",
    "hisoty_rec = model_rec.fit(X_rec, y_rec, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_ru = recovered_ru['Province_State']\n",
    "last_date = pd.to_datetime(recovered_ru.columns.values[-1:]).date[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "93/93 [==============================] - 7s 73ms/step - loss: 111.0129\n",
      "Epoch 2/10\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 102.5468\n",
      "Epoch 3/10\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 96.6347\n",
      "Epoch 4/10\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 89.0841\n",
      "Epoch 5/10\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 80.3686\n",
      "Epoch 6/10\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 70.0201\n",
      "Epoch 7/10\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 58.8572\n",
      "Epoch 8/10\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 44.9057\n",
      "Epoch 9/10\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 31.6205\n",
      "Epoch 10/10\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 20.3481\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_steps = 3\n",
    "n_features = 85\n",
    "model_deaths = build_model_simple(n_steps,n_features)\n",
    "\n",
    "dataset_deaths = get_dataset_ru(deaths_ru) \n",
    "X_deaths,y_deaths = split_sequences(dataset_deaths,n_steps)\n",
    "hisoty_deaths = model_deaths.fit(X_deaths, y_deaths, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prediction:\n",
    "    def __init__(self, model,last_date,columns_df):\n",
    "        self.columns_df = columns_df\n",
    "        self.model = model\n",
    "        self.last_date = last_date\n",
    "        self.predion_date = self.__make_date_predition()\n",
    "        self.size_prediction = len(self.predion_date)\n",
    "        \n",
    "    def predict(self,dataset):\n",
    "        self.dateset = dataset\n",
    "        matrix_prediction = self.__make_prediction_matrix()\n",
    "        return self.__make_dataframe_prediction(matrix_prediction)\n",
    "    \n",
    "    def __make_dataframe_prediction(self,matrix_prediction):\n",
    "        df = pd.DataFrame(matrix_prediction,columns=self.columns_df)\n",
    "        df['date'] = self.predion_date\n",
    "        return df\n",
    "    def __make_prediction_matrix(self):\n",
    "        dataset = self.dateset\n",
    "        model = self.model\n",
    "        count = self.size_prediction\n",
    "        \n",
    "        x = np.array([dataset[-3:,:]])\n",
    "        x_i = dataset[-2:,:]\n",
    "        result = []\n",
    "        for _ in range(count):\n",
    "            y_pred = model.predict(x)[0]\n",
    "    #         y_pred_ = list(np.sign(y_pred)*(y_pred))\n",
    "            y_pred_ = list((y_pred))\n",
    "            result.append(y_pred_)\n",
    "            y_pred = y_pred.reshape(1,85)\n",
    "            x = np.vstack((x_i,y_pred))\n",
    "            x_i = x[-2:,:]\n",
    "            x = np.array([x])\n",
    "        return result\n",
    "        \n",
    "    def __make_date_predition(self):\n",
    "        last_date = self.last_date\n",
    "        last_date += timedelta(days=1)\n",
    "        res_date = []\n",
    "        while last_date< date(2021,1,1):\n",
    "            res_date.append(last_date)\n",
    "            last_date += timedelta(days=1)\n",
    "        return res_date\n",
    "        \n",
    "        \n",
    "    \n",
    "class Submission:\n",
    "    def __init__(self,columns_df,date_prediction):\n",
    "        self.columns_df = columns_df\n",
    "        self.date_prediction = date_prediction\n",
    "        \n",
    "    def submit(self,rec_df,deaths_df,mapper):\n",
    "        df_res = pd.DataFrame({}) \n",
    "        for column in self.columns_df:\n",
    "            df_res_ = pd.DataFrame({}) \n",
    "            df_res_['date'] = self.date_prediction\n",
    "            df_res_['region'] = [column]*len(self.date_prediction)\n",
    "            df_res_['prediction_confirmed'] = rec_df[column]\n",
    "            df_res_['prediction_deaths'] = deaths_df[column]\n",
    "            \n",
    "            df_res = pd.concat([df_res,df_res_],axis=0)\n",
    "        df_res.index=np.arange(df_res.shape[0])\n",
    "        df_res.region = df_res.region.map(mapper)\n",
    "        return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictioner_rec = Prediction(model_rec,last_date,columns_ru)\n",
    "df_pred_rec = predictioner_rec.predict(dataset_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictioner_deaths = Prediction(model_deaths,last_date,columns_ru)\n",
    "df_pred_deaths = predictioner_deaths.predict(dataset_deaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissioner = Submission(columns_ru,predictioner_rec.predion_date)\n",
    "subm = submissioner.submit(df_pred_rec,df_pred_deaths,mapper_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21165, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm.to_csv('subm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
